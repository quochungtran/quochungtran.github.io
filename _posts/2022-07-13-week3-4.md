---
layout: "post"
title: "<Weeks 3,4> Preprocessing for improving the quality of the output"
categories: "junk"
date: "2022-06-14 16:41:53 +0200"
author:
  - "TRAN Quoc Hung"
meta: "Springfield"

---

In the following weeks (July 11,2022 to July 25, 2022), for each test case, I will try to :

- Improve algorithms for pre-processing image.
- Testing Post-processing for all general cases.  

Based on the results of previous research, I realize that Tesseract does various processing internally before doing the actual OCR. However, some instances still exist where Tesseract can result in a signification reduction in accuracy. 

So in this post, I would like to introduce some pre-processing methods that apply directly before passing in Tesseract.

# **Removing Shadow** 

- The main idea is to extract and segment the text from each channel by using Background subtraction (BS) from the grayscale image, which is a common and widely used technique for generating a foreground mask. 

- BS calculates the foreground mask performing a subtraction between the current frame and a background model, containing the static part of the scene or, more in general, everything that can be considered as background given the characteristics of the observed scene.

- The purpose is to remove the shadow or noise from background of each test case (in each set case here the background of scanned image can be influenced by many external factors)(convert the background into white or black) and then merge each track into an image.  

For simplify, here is an example, we can see the Tesseract output can be affected by the light.  

![figure1](https://github.com/quochungtran/Gsoc2022-tesseract-ocr/blob/master/data/shadow_page_book.png?raw=true)

Please look at three picture channels; the amount of shadow in blue in the channel is the most distributed.

![figure1](https://github.com/quochungtran/Gsoc2022-tesseract-ocr/blob/master/image_blog/bl2_1.png?raw=true)


## Implementation
### First step 

Extract the background by making blur the part of the text. Morphological operations are helpful right now. 

- Grayscale dilation of an image involves assigning to each pixel the maximum value found over the neighborhood of the structuring element by using a square kernel with odd-dimensional (kernel 3 x 3).

- The dilated value of a pixel x is the maximum value of the image in the neighborhood defined.

Dilation is considered a type of morphological operation. Morphological operations are the set of operations that process images according to their shapes.As the kernel B is scanned over the image, we compute the maximal pixel value overlapped by B and replace the image pixel in the anchor point position with that maximal value. As you can deduce, with background with and black text, this maximizing operation causes dark regions within an image to reduce. The bigger size of the kernel is, the blurrier text is. They are transferred as noise as we need to remove. 


![figure1](https://github.com/quochungtran/Gsoc2022-tesseract-ocr/blob/master/image_blog/bl2_2.png?raw=true)

### Second step 

Median Blur helps smooth image and remove noise produced from previous operations. They take each background more generally.



![figure1](https://github.com/quochungtran/Gsoc2022-tesseract-ocr/blob/master/image_blog/bl2_3.png?raw=true)

### Third step 

cv2.absdiff is a function that helps find the absolute difference between the pixels of the two image arrays. Using this, we can extract just the pixels of the text of the objects. Or on the other way, the background becomes white; the shadow is all removed. 


![figure1](https://github.com/quochungtran/Gsoc2022-tesseract-ocr/blob/master/image_blog/bl2_4.png?raw=true)

And finally, merging all channels into one image, we get the following result. We can see the noise in background is removed, we obtain of course a better output.   

![figure1](https://github.com/quochungtran/Gsoc2022-tesseract-ocr/blob/master/image_blog/results_remove_shadow.png?raw=true)


Here is more the example test cases that I have tried, and all we almost get the better results: 

![figure1](https://github.com/quochungtran/Gsoc2022-tesseract-ocr/blob/master/image_blog/bl2_5.png?raw=true)

![figure1](https://github.com/quochungtran/Gsoc2022-tesseract-ocr/blob/master/image_blog/bl2_6.png?raw=true)


